{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[range(0, 20),\n",
       " range(20, 35),\n",
       " range(35, 45),\n",
       " range(45, 60),\n",
       " range(60, 70),\n",
       " range(70, 85)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_seqs_by_list(lens):\n",
    "    seqs = []\n",
    "    start = 0\n",
    "    for l in lens:\n",
    "        seqs.append(range(start, start+l))\n",
    "        start = start+l\n",
    "    return seqs;\n",
    "\n",
    "split_seqs_by_list([20,15,10,15,10,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the required modules:\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "\n",
    "# Define folder paths:\n",
    "DATA_folder  = '../../Data/'\n",
    "CLUSTER_folder = DATA_folder+'Clusters/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdbscan_params  = {}\n",
    "\n",
    "for k in range(0,10):\n",
    "    data = np.load(CLUSTER_folder+'train_'+str(k)+'.npy')\n",
    "    for c in range(2,11):\n",
    "        for s in [1,c]:\n",
    "            clusterer = hdbscan.HDBSCAN(min_cluster_size=c,min_samples=s)\n",
    "            cluster_labels = clusterer.fit_predict(data)\n",
    "            m = max(cluster_labels)\n",
    "            n = sum(cluster_labels==-1)\n",
    "            # hdbscan_params[('dig: '+str(k),'size: '+str(c),'smpl: '+str(s))] = ('clusters: '+str(m+1),'noise: '+str(n))\n",
    "            hdbscan_params[(k,c,s)] = {'clusters':m+1,'noise':n}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(CLUSTER_folder+'hdbscan_params.npy',hdbscan_params)\n",
    "\n",
    "# b = np.load(CLUSTER_folder+'hdbscan_params.npy').item()\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters:  1082.0  \t noise:  2941.0\n",
      "clusters:  1082.0  \t noise:  2941.0\n",
      "clusters:  2.0  \t noise:  99.0\n",
      "clusters:  2.0  \t noise:  99.0\n",
      "clusters:  2.0  \t noise:  159.0\n",
      "clusters:  1.0  \t noise:  77.0\n",
      "clusters:  1.0  \t noise:  77.0\n",
      "clusters:  2.0  \t noise:  159.0\n",
      "clusters:  1.0  \t noise:  885.0\n",
      "clusters:  1.0  \t noise:  77.0\n",
      "clusters:  1.0  \t noise:  77.0\n",
      "clusters:  2.0  \t noise:  1242.0\n",
      "clusters:  1.0  \t noise:  1766.0\n",
      "clusters:  2.0  \t noise:  3257.0\n",
      "clusters:  1.0  \t noise:  621.0\n",
      "clusters:  1.0  \t noise:  621.0\n",
      "clusters:  1.0  \t noise:  876.0\n",
      "clusters:  1.0  \t noise:  2462.0\n",
      "clusters:  2.0  \t noise:  3257.0\n",
      "clusters:  1.0  \t noise:  3372.0\n",
      "clusters:  1.0  \t noise:  621.0\n",
      "clusters:  1.0  \t noise:  621.0\n",
      "clusters:  2.0  \t noise:  1979.0\n",
      "clusters:  1.0  \t noise:  2462.0\n",
      "clusters:  1.0  \t noise:  3091.0\n",
      "clusters:  6.0  \t noise:  5354.0\n",
      "clusters:  5.0  \t noise:  5439.0\n",
      "clusters:  1.0  \t noise:  621.0\n",
      "clusters:  1.0  \t noise:  621.0\n",
      "clusters:  1.0  \t noise:  1986.0\n",
      "clusters:  2.0  \t noise:  3456.0\n",
      "clusters:  1.0  \t noise:  3091.0\n",
      "clusters:  5.0  \t noise:  5361.0\n",
      "clusters:  1.0  \t noise:  5167.0\n",
      "clusters:  1.0  \t noise:  5219.0\n",
      "clusters:  1.0  \t noise:  621.0\n",
      "clusters:  1.0  \t noise:  621.0\n",
      "clusters:  3.0  \t noise:  3868.0\n",
      "clusters:  1.0  \t noise:  3464.0\n",
      "clusters:  1.0  \t noise:  3091.0\n",
      "clusters:  1.0  \t noise:  4968.0\n",
      "clusters:  1.0  \t noise:  5468.0\n",
      "clusters:  1.0  \t noise:  5219.0\n",
      "clusters:  1.0  \t noise:  5779.0\n",
      "clusters:  1.0  \t noise:  621.0\n",
      "clusters:  1.0  \t noise:  621.0\n",
      "clusters:  1.0  \t noise:  3197.0\n",
      "clusters:  5.0  \t noise:  4995.0\n",
      "clusters:  3.0  \t noise:  5208.0\n",
      "clusters:  1.0  \t noise:  5396.0\n",
      "clusters:  1.0  \t noise:  5468.0\n",
      "clusters:  2.0  \t noise:  5448.0\n",
      "clusters:  1.0  \t noise:  5779.0\n",
      "clusters:  1.0  \t noise:  5785.0\n"
     ]
    }
   ],
   "source": [
    "lbls_found = np.load('lbls_found.npy')\n",
    "noise      = np.load('noise.npy')\n",
    "\n",
    "k = 4\n",
    "for c in range(2,11):\n",
    "    for s in range(1,c+1):\n",
    "        print('clusters: ',lbls_found[k,c,s],' \\t noise: ',noise[k,c,s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
