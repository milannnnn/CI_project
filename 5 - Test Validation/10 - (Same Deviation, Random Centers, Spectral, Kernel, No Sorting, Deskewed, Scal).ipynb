{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Importing Modules and MNIST Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NumPy and SciPy modules:\n",
    "import numpy as np\n",
    "from scipy.ndimage import interpolation\n",
    "# SciKit Learn Modules:\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "# Dask Modules (for Grid Search):\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask_searchcv import GridSearchCV\n",
    "# Additional modules:\n",
    "import random,time,gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing MNIST Data:\n",
    "DATA_folder  = '../../Data/'\n",
    "data = np.load(DATA_folder+'train_imgs.npy')\n",
    "lbls = np.load(DATA_folder+'train_lbls.npy')\n",
    "test_data = np.load(DATA_folder+'test_imgs.npy')\n",
    "test_lbls = np.load(DATA_folder+'test_lbls.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Definition Scikit-Learn Transformer Objects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of Deskewing Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SKLEARN Compatible Transformer - Image Deskewing Transformation\n",
    "class myDeskewer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # Transformer initialization\n",
    "    def __init__(self, debug=False):\n",
    "        self.debug = debug\n",
    "    \n",
    "    # No fitting required:\n",
    "    def fit(self, X=None, y=None):        \n",
    "        return self\n",
    "    \n",
    "    # Definition of Moments Calculation Function\n",
    "    @staticmethod\n",
    "    def moments(image):\n",
    "        # Create mesh grids for centroid calculation:\n",
    "        c0,c1 = np.mgrid[:image.shape[0],:image.shape[1]] # A trick in numPy to create a mesh grid\n",
    "        # Calculate Total Image weight:\n",
    "        totalImage = np.sum(image) #sum of pixels\n",
    "        # Calculate image centroids:\n",
    "        m0 = np.sum(c0*image)/totalImage # mu_x\n",
    "        m1 = np.sum(c1*image)/totalImage # mu_y\n",
    "        # Calculate image variance and covariance\n",
    "        var = np.sum((c0-m0)**2*image)/totalImage      # Var(x)\n",
    "        cov = np.sum((c0-m0)*(c1-m1)*image)/totalImage # Cov(x,y)\n",
    "        mu_vector = np.array([m0,m1])\n",
    "        alpha = cov/var\n",
    "        return mu_vector, alpha\n",
    "\n",
    "    # Definition of Deskewing Function:\n",
    "    @staticmethod\n",
    "    def deskew(img):\n",
    "        image = img.reshape(28,28)\n",
    "        c,alpha = myDeskewer.moments(image)\n",
    "        # Define transformation matrix:\n",
    "        affine = np.array([[1,0],[alpha,1]])\n",
    "        # Define transformation offset:\n",
    "        ocenter = np.array(image.shape)/2.0\n",
    "        offset = c-np.dot(affine,ocenter)\n",
    "        # Return affine_transformation\n",
    "        return interpolation.affine_transform(image,affine,offset=offset).reshape(28*28)\n",
    "    \n",
    "    # Clculate Kernel Components based on obtained model\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        if self.debug:\n",
    "            print('Applying Deskewing Transformation!!!')\n",
    "            t = time.time()\n",
    "        # Preallocate memory:\n",
    "        new_data = np.empty(X.shape)\n",
    "        \n",
    "        # Loop over each image:\n",
    "        for k in range(X.shape[0]):\n",
    "            new_data[k]=myDeskewer.deskew(X[k])\n",
    "            \n",
    "        if self.debug:\n",
    "            print('Deskewing Transformation finished in: ',(time.time()-t))\n",
    "        \n",
    "        return new_data\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of Batch Kernel PCA Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Due to high memory requirements - we cannot process the whole dataset with kPCA - we need to sample a random batch!!!\n",
    "\n",
    "# SKLEARN Compatible Transformer - supports fit method (finding kPCA) and transform method (applying kPCA)\n",
    "class myKernelPCA(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # Transformer initialization (default to 250 dimensions)\n",
    "    def __init__(self, n_kPCA=250, kernel = 'poly', degree=4, whiten=True, debug=False):\n",
    "        self.n_kPCA    = n_kPCA # number of kernel PCA dimensions to be retained\n",
    "        self.kernel    = kernel # kernel type (rbf, poly, cosine)\n",
    "        self.degree    = degree # poly kernel degree\n",
    "        #self.whiten    = whiten # whiten data at output layer (zero mean, un var)\n",
    "        self.whiten    = whiten and (kernel!='laplacian') and (kernel!='rbf')\n",
    "        self.debug     = debug  # debug flag\n",
    "        self.max_smpls = 250    # max number of samples per digit\n",
    "    \n",
    "    # Clusters each digit and finds cluster centers:\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.kPCA = KernelPCA(n_components=self.n_kPCA,kernel=self.kernel,degree=self.degree,copy_X=False,remove_zero_eig=True,random_state=1389)\n",
    "        \n",
    "        if self.debug:\n",
    "            print('Fitting Kernel PCA !!!')\n",
    "            t = time.time()\n",
    "        \n",
    "        # If we have less than max number of smpls - fit regular kPCA\n",
    "        if X.shape[0]<(self.max_smpls*10):\n",
    "            self.kPCA.fit(X)\n",
    "            # If required - whiten the data (for clustering)\n",
    "            if self.whiten:\n",
    "                self.scaler = StandardScaler().fit(self.kPCA.transform(X))\n",
    "        \n",
    "        # Else randomly pick max number of smpls for each digit and fit\n",
    "        else:\n",
    "            # Fix the random seed (for repeatable results)\n",
    "            prng = np.random.RandomState()\n",
    "            prng.seed(654)\n",
    "            # Check how many smps are available per digit\n",
    "            l = []\n",
    "            for dig in range(10):\n",
    "                l.append(min(self.max_smpls,sum(y==dig)))\n",
    "            # Preallocate memory\n",
    "            new_data = np.empty((sum(l),X.shape[1]))\n",
    "            # Fill with randomly drawn smpls\n",
    "            st = 0\n",
    "            for dig in range(10):\n",
    "                en = st+l[dig]\n",
    "                data  = X[y==dig]\n",
    "                smpls = prng.choice(data.shape[0],l[dig],replace=False)\n",
    "                new_data[st:en,] = data[smpls,]\n",
    "                st = en\n",
    "            # Fit KernelPCA to new_data\n",
    "            self.kPCA.fit(new_data)\n",
    "            # If required - whiten the data (for clustering)\n",
    "            if self.whiten:\n",
    "                self.scaler = StandardScaler().fit(self.kPCA.transform(new_data))\n",
    "            # Release old vars, and collect garbage\n",
    "            del data, smpls, new_data\n",
    "            gc.collect()\n",
    "            \n",
    "        if self.debug:\n",
    "            print('Kernel PCA fitted in: ',(time.time()-t))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # Clculate Kernel Components based on obtained model\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        if self.debug:\n",
    "            print('Applying Kernel PCA transformation!!! (data', X.shape,')')\n",
    "            t = time.time()\n",
    "        # Preallocate memory:\n",
    "        new_data = np.empty((X.shape[0],self.kPCA.lambdas_.shape[0]))\n",
    "        st = 0\n",
    "        ch = 200\n",
    "        ns = X.shape[0]\n",
    "        # Transform data in chunks of 200 smpls (memory hungry transformation)\n",
    "        while st<ns:\n",
    "            en = min(st+ch,ns)\n",
    "            new_data[st:en,:] = self.kPCA.transform(X[st:en,:])\n",
    "            st = en\n",
    "        \n",
    "        if self.whiten:\n",
    "            new_data = self.scaler.transform(new_data)\n",
    "                \n",
    "        if self.debug:\n",
    "            print('Kernel PCA transformed in: ',time.time()-t)\n",
    "        \n",
    "        return new_data\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of RBF Transformer (sklearn compatible object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SKLEARN Compatible Transformer - supports fit method (custering data) and transform method (calculating fi values)\n",
    "class myRBFtransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # Transformer initialization (default to 50 kMeans clusters)\n",
    "    def __init__(self, n_centers=250, rn_ratio=0.1, cl_ratio=0.5, debug=False):\n",
    "        self.n_centers = n_centers              # number of data centers to be formed per digit\n",
    "        self.rn_ratio  = min(1,max(0,rn_ratio)) # random  ratio (between Random Selection and Clustering)\n",
    "        self.cl_ratio  = min(1,max(0,cl_ratio)) # cluster ratio (between kMeans and Agglomerative)\n",
    "        self.debug     = debug                  # debug flag\n",
    "        if self.debug:\n",
    "            print(self.n_centers,self.cl_ratio)\n",
    "    \n",
    "    # Function for data clustering, and computation of cluster center vectors and inv. sq. deviation vectors\n",
    "    @staticmethod\n",
    "    def form_clusters(data, n_kmeans, n_agglo, n_random, dig):\n",
    "\n",
    "        n_km = min(n_kmeans,data.shape[0])\n",
    "        n_ag = min(n_agglo ,data.shape[0])\n",
    "        n_rn = min(n_random,data.shape[0])\n",
    "\n",
    "        lbls_set = []\n",
    "\n",
    "        if n_km>0:\n",
    "            kmeans = KMeans(n_clusters=n_km, random_state=0, init='k-means++', algorithm='elkan')\n",
    "            lbls_kmeans = kmeans.fit_predict(data)\n",
    "            lbls_set.append(lbls_kmeans)\n",
    "\n",
    "        if n_ag>0:\n",
    "            #agglo  = SpectralClustering(n_clusters=n_ag, affinity='nearest_neighbors',eigen_solver='arpack',random_state=456,assign_labels='discretize')\n",
    "            agglo  = SpectralClustering(n_clusters=n_ag, affinity='sigmoid',eigen_solver='arpack',random_state=456,assign_labels='discretize')\n",
    "            lbls_agglo  = agglo.fit_predict(data)\n",
    "            lbls_set.append(lbls_agglo)\n",
    "\n",
    "        centers     = []\n",
    "\n",
    "        # Find cluster centers and covar matrix:\n",
    "        for lbls in lbls_set:\n",
    "            for k in range(max(lbls)+1):\n",
    "                cluster = data[lbls==k,:]\n",
    "                centers.append(cluster.mean(axis=0))\n",
    "\n",
    "            del cluster\n",
    "\n",
    "        # Add random points as centers:\n",
    "        if n_rn>0:\n",
    "            # seed a new random generator (to get repeatable results for hyperparam tuning)\n",
    "            prng = np.random.RandomState()\n",
    "            prng.seed(dig*n_rn)\n",
    "            smpls = prng.choice(data.shape[0],n_rn,replace=False)\n",
    "            for s in smpls:\n",
    "                centers.append(data[s,:])\n",
    "\n",
    "        return centers;\n",
    "    \n",
    "    # Clusters each digit and finds cluster centers:\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.centers     = [] # list of cluster center vectors\n",
    "        self.num_centers = [] # list of number of centers per digit\n",
    "        \n",
    "        # Calc. num. of clusters per digit based on assigned ratio (ratio*(num of smpls / 10))\n",
    "        n_random   = round(self.rn_ratio*self.n_centers)\n",
    "        n_clusters = self.n_centers - n_random\n",
    "        n_kmeans   = round(self.cl_ratio*n_clusters)\n",
    "        n_agglo    = n_clusters - n_kmeans\n",
    "        \n",
    "        if self.debug:\n",
    "            print('Clustering data ',(n_kmeans,n_agglo))\n",
    "            t = time.time()\n",
    "        \n",
    "        # Cluster the data over each digit\n",
    "        for dig in range(10):\n",
    "            # print('Clustering digit: ',dig)\n",
    "            data = X[y==dig,:]\n",
    "            centers = myRBFtransformer.form_clusters(data, n_kmeans, n_agglo, n_random, dig)\n",
    "            self.centers.extend(centers)\n",
    "            self.num_centers.append(len(centers))\n",
    "            \n",
    "        if self.debug:\n",
    "            print('Clustering time: ',(time.time()-t))\n",
    "        \n",
    "        del data, centers\n",
    "        gc.collect()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # Function to compute whole Fi output for given dataset (for all RBF centers)\n",
    "    @staticmethod\n",
    "    def fi_transform(data, all_centers):\n",
    "        # data        - given dataset matrix for which to compute fi values\n",
    "        # center      - list of all center vectors on which to compute fi vals\n",
    "\n",
    "        new_data = np.empty((data.shape[0],len(all_centers)))\n",
    "        st = 0\n",
    "        ch = 200\n",
    "        ns = data.shape[0]\n",
    "        # Process data in chunks of 200 smpls (optimal speed)\n",
    "        while st<ns:\n",
    "            en = min(st+ch,ns)\n",
    "            for k in range(len(all_centers)):\n",
    "                # # SAME DEVIATION for ALL DIMENSIONS (better much better than cluster separate):\n",
    "                new_data[st:en,k] = (np.square(data[st:en] - np.repeat(all_centers[k][np.newaxis,:],en-st,axis=0))).mean(axis=1)\n",
    "            new_data[st:en,:] = np.exp(-np.sqrt(new_data[st:en,:]))\n",
    "            st = en\n",
    "            gc.collect()\n",
    "        return new_data\n",
    "    \n",
    "    # Computes fi values (with Gaussian function) based on obtained data centers\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Compute all Fi values:\n",
    "        if self.debug:\n",
    "            print('Calculating all Fi outputs !!! (data', X.shape,')')\n",
    "            t = time.time()\n",
    "        all_fis = myRBFtransformer.fi_transform(X, self.centers)\n",
    "        \n",
    "        if self.debug:\n",
    "            print('Fi calculation time: ',time.time()-t)\n",
    "        \n",
    "        return all_fis\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Layer Linking (pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_kPCA    = 40\n",
    "kernel    = 'laplacian'\n",
    "n_centers = 50\n",
    "rn_ratio  = 0.75\n",
    "cl_ratio  = 1.0\n",
    "C         = 1e3\n",
    "tol       = 1e-6\n",
    "debug     = False\n",
    "\n",
    "dskw   = myDeskewer(debug=debug)\n",
    "scaler = StandardScaler()\n",
    "pca    = myKernelPCA(kernel=kernel,n_kPCA=n_kPCA,debug=debug)\n",
    "rbf    = myRBFtransformer(n_centers=n_centers,rn_ratio=rn_ratio,cl_ratio=cl_ratio, debug=debug)\n",
    "scaler2 = StandardScaler()\n",
    "clsf   = LogisticRegression(tol=tol,C=C,random_state=12,solver='liblinear')\n",
    "# clsf = RandomForestClassifier(n_estimators=100, max_features='sqrt' , max_depth=None, min_samples_split=2, random_state=12121)\n",
    "# clsf = LogisticRegression(tol=tol,C=C,random_state=12,solver='newton-cg',multi_class='multinomial',max_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('dskw',dskw),('scal', scaler), ('pca', pca), ('rbf',rbf),('scal2', scaler2), ('clsf',clsf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of Search Space:\n",
    "\n",
    "Ks  = [250]\n",
    "n_jobs =-1\n",
    "RNs = [0.6] # Random Ratio\n",
    "NKs = [40]\n",
    "Cs  = [1e3]\n",
    "tols= [1e-6]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'pca__n_kPCA':        NKs,\n",
    "        'rbf__n_centers':     Ks,\n",
    "        'rbf__rn_ratio':      RNs,\n",
    "        'clsf__tol':          tols,\n",
    "        'clsf__C':            Cs,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definition of Train-Test Split:\n",
    "\n",
    "test_fold = [-1]*data.shape[0]+[0]*test_data.shape[0]\n",
    "ps = PredefinedSplit(test_fold)\n",
    "\n",
    "tot_data = np.vstack((data,test_data))\n",
    "tot_lbls = np.hstack((lbls,test_lbls))\n",
    "\n",
    "del data,test_data,lbls,test_lbls\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, cv=ps, n_jobs=n_jobs, param_grid=param_grid, refit=False, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Different Kernels (logreg: tol = 1e-3, C=1e3; 60k trainset):\n",
    "# ------------------\n",
    "# FULL kMEANS:\n",
    "# \n",
    "# laplacian - 94.46%\n",
    "# rbf       - 93.24%\n",
    "# poly_3    - 92.95%\n",
    "# sigmoid   - 91.72%\n",
    "# poly_6    - 90.82%\n",
    "# ------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[################################        ] | 81% Completed |  3hr  1min 49.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-646b80d1bb91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mProgressBar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtot_lbls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask_searchcv\\model_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mscheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_normalize_scheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_deprecated_train_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\threaded.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(dsk, result, cache, num_workers, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     results = get_async(pool.apply_async, len(pool._pool), dsk, result,\n\u001b[0;32m     74\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                         pack_exception=pack_exception, **kwargs)\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m# Cleanup pools associated to dead threads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mget_async\u001b[1;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[0;32m    510\u001b[0m             \u001b[1;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'waiting'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ready'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'running'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m                 \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    171\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    grid.fit(tot_data, tot_lbls)\n",
    "    \n",
    "print(max(grid.cv_results_['mean_test_score'])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### Parameter Grid:\\n')\n",
    "for k in range(len(grid.cv_results_['params'])):\n",
    "    print(grid.cv_results_['params'][k])\n",
    "    sc  = np.round(grid.cv_results_['mean_test_score'][k]*100,2)\n",
    "    ftm = np.round(grid.cv_results_['mean_fit_time'][k])\n",
    "    stm = np.round(grid.cv_results_['mean_score_time'][k])\n",
    "    #print('Score:',sc,'%; Fit time:',ftm,'s; Score Time:',stm,'s;\\n')\n",
    "    tsc = np.round(grid.cv_results_['mean_train_score'][k]*100,2)\n",
    "    print('Test Score:',sc,'%; Train Score:',tsc,'%; Fit time:',ftm,'s; Score Time:',stm,'s;\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Parameter Grid (for 250 centers):\n",
    "\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.0}\n",
    "# Test Score: 97.79 %; Train Score: 97.93 %; Fit time: 6478.0 s; Score Time: 3956.0 s;\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.1}\n",
    "# Test Score: 97.79 %; Train Score: 97.92 %; Fit time: 6528.0 s; Score Time: 3967.0 s;\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.2}\n",
    "# Test Score: 97.81 %; Train Score: 97.91 %; Fit time: 6528.0 s; Score Time: 3962.0 s;\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.3}\n",
    "# Test Score: 97.8 %; Train Score: 97.92 %; Fit time: 6456.0 s; Score Time: 3146.0 s;\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.4}\n",
    "# Test Score: 97.79 %; Train Score: 97.9 %; Fit time: 6438.0 s; Score Time: 3144.0 s;\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.81 %; Train Score: 97.9 %; Fit time: 6435.0 s; Score Time: 3143.0 s;\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.6}\n",
    "# Test Score: 97.83 %; Train Score: 97.89 %; Fit time: 6377.0 s; Score Time: 3144.0 s;\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.7}\n",
    "# Test Score: 97.69 %; Train Score: 97.83 %; Fit time: 5213.0 s; Score Time: 1554.0 s;\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.8}\n",
    "# Test Score: 97.82 %; Train Score: 97.83 %; Fit time: 5133.0 s; Score Time: 1580.0 s;\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.9}\n",
    "# Test Score: 97.75 %; Train Score: 97.82 %; Fit time: 4976.0 s; Score Time: 1493.0 s;\n",
    "# {'clsf__C': 1000.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 1}\n",
    "# Test Score: 97.79 %; Train Score: 97.88 %; Fit time: 6187.0 s; Score Time: 3754.0 s;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Parameter Grid (for 500 centers):\n",
    "\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.0}\n",
    "# Test Score: 97.22 %; Train Score: 97.11 %; Fit time: 5351.0 s; Score Time: 103.0 s;\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.1}\n",
    "# Test Score: 97.21 %; Train Score: 97.09 %; Fit time: 5384.0 s; Score Time: 105.0 s;\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.2}\n",
    "# Test Score: 97.2 %; Train Score: 97.05 %; Fit time: 5097.0 s; Score Time: 76.0 s;\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.3}\n",
    "# Test Score: 97.21 %; Train Score: 97.07 %; Fit time: 5011.0 s; Score Time: 101.0 s;\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.4}\n",
    "# Test Score: 97.21 %; Train Score: 97.04 %; Fit time: 5164.0 s; Score Time: 106.0 s;\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.19 %; Train Score: 97.04 %; Fit time: 5161.0 s; Score Time: 103.0 s;\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.6}\n",
    "# Test Score: 97.16 %; Train Score: 97.03 %; Fit time: 5031.0 s; Score Time: 109.0 s;\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.7}\n",
    "# Test Score: 97.2 %; Train Score: 97.01 %; Fit time: 5325.0 s; Score Time: 113.0 s;\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.8}\n",
    "# Test Score: 97.13 %; Train Score: 97.01 %; Fit time: 5128.0 s; Score Time: 86.0 s;\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.9}\n",
    "# Test Score: 97.12 %; Train Score: 96.96 %; Fit time: 3965.0 s; Score Time: 66.0 s;\n",
    "# {'clsf__C': 100.0, 'clsf__tol': 1e-06, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 1}\n",
    "# Test Score: 97.09 %; Train Score: 96.97 %; Fit time: 4911.0 s; Score Time: 106.0 s;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# {'clsf__C': 1000000.0, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 98.82 %; Train Score: 99.78 %; Fit time: 75322.0 s; Score Time: 63.0 s;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Different Cs (log reg):\n",
    "\n",
    "### Parameter Grid:\n",
    "\n",
    "# {'clsf__C': 1000000.0, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 98.76 %; Train Score: 99.6 %; Fit time: 22907.0 s; Score Time: 4094.0 s;\n",
    "\n",
    "# {'clsf__C': 1000000000.0, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 98.75 %; Train Score: 99.62 %; Fit time: 23035.0 s; Score Time: 3981.0 s;\n",
    "\n",
    "# {'clsf__C': 1000000000000.0, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 98.77 %; Train Score: 99.62 %; Fit time: 23135.0 s; Score Time: 3891.0 s;\n",
    "\n",
    "# {'clsf__C': 1000000000000000.0, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 98.74 %; Train Score: 99.65 %; Fit time: 23758.0 s; Score Time: 3606.0 s;\n",
    "\n",
    "# {'clsf__C': 1e+18, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 98.78 %; Train Score: 99.6 %; Fit time: 13196.0 s; Score Time: 495.0 s;\n",
    "\n",
    "# {'clsf__C': 1e+21, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 98.78 %; Train Score: 99.58 %; Fit time: 13037.0 s; Score Time: 561.0 s;\n",
    "\n",
    "\n",
    "# {'clsf__C': 1000000.0, 'pca__n_kPCA': 40, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 98.82 %; Train Score: 99.78 %; Fit time: 75322.0 s; Score Time: 63.0 s;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Different Number of kPCA:\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 20, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.57 %; Train Score: 97.66 %; Fit time: 7589.0 s; Score Time: 362.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 30, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.78 %; Train Score: 97.87 %; Fit time: 7278.0 s; Score Time: 667.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 35, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.79 %; Train Score: 97.86 %; Fit time: 6955.0 s; Score Time: 3144.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 38, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.75 %; Train Score: 97.86 %; Fit time: 6748.0 s; Score Time: 3119.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 40, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.81 %; Train Score: 97.9 %; Fit time: 6951.0 s; Score Time: 973.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 42, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.78 %; Train Score: 97.85 %; Fit time: 6746.0 s; Score Time: 3123.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 45, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.72 %; Train Score: 97.81 %; Fit time: 6742.0 s; Score Time: 3111.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 50, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.78 %; Train Score: 97.79 %; Fit time: 6582.0 s; Score Time: 1326.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 100, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.42 %; Train Score: 97.42 %; Fit time: 5462.0 s; Score Time: 3383.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 150, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.25 %; Train Score: 97.24 %; Fit time: 5212.0 s; Score Time: 3358.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 200, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.13 %; Train Score: 97.1 %; Fit time: 5211.0 s; Score Time: 3306.0 s;\n",
    "\n",
    "# {'clsf__C': 1000.0, 'pca__n_kPCA': 250, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 96.98 %; Train Score: 96.99 %; Fit time: 5207.0 s; Score Time: 3358.0 s;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LOGISTIC REGRESSION:\n",
    "\n",
    "# {'logreg__C': 1000.0, 'pca__n_kPCA': 29, 'rbf__n_centers': 50, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 96.88 %; Train Score: 96.7 %; Fit time: 1306.0 s; Score Time: 72.0 s;\n",
    "\n",
    "# {'logreg__C': 1000.0, 'pca__n_kPCA': 29, 'rbf__n_centers': 100, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.35 %; Train Score: 97.29 %; Fit time: 2531.0 s; Score Time: 81.0 s;\n",
    "\n",
    "# {'logreg__C': 1000.0, 'pca__n_kPCA': 29, 'rbf__n_centers': 150, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.61 %; Train Score: 97.58 %; Fit time: 3725.0 s; Score Time: 70.0 s;\n",
    "\n",
    "# {'logreg__C': 1000.0, 'pca__n_kPCA': 29, 'rbf__n_centers': 200, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.71 %; Train Score: 97.74 %; Fit time: 4742.0 s; Score Time: 59.0 s;\n",
    "\n",
    "# {'logreg__C': 1000.0, 'pca__n_kPCA': 29, 'rbf__n_centers': 250, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.75 %; Train Score: 97.85 %; Fit time: 4741.0 s; Score Time: 50.0 s;\n",
    "\n",
    "# {'logreg__C': 1000.0, 'pca__n_kPCA': 29, 'rbf__n_centers': 400, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 97.93 %; Train Score: 98.14 %; Fit time: 8134.0 s; Score Time: 69.0 s;\n",
    "\n",
    "# {'logreg__C': 1000.0, 'pca__n_kPCA': 29, 'rbf__n_centers': 500, 'rbf__rn_ratio': 0.5}\n",
    "# Test Score: 98.04 %; Train Score: 98.25 %; Fit time: 9869.0 s; Score Time: 63.0 s;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Parameter Grid:\n",
    "\n",
    "# {'logreg__C': 1000.0, 'pca__n_kPCA': 29, 'rbf__n_centers': 10, 'rbf__rn_ratio': 0.0}\n",
    "# Test Score: 95.64 %; Train Score: 95.28 %; Fit time: 339.0 s; Score Time: 37.0 s;\n",
    "\n",
    "# ### Parameter Grid:\n",
    "\n",
    "# {'logreg__C': 1000.0, 'pca__n_kPCA': 29, 'rbf__n_centers': 10, 'rbf__rn_ratio': 0.0}\n",
    "# Test Score: 95.64 %; Train Score: 95.28 %; Fit time: 336.0 s; Score Time: 37.0 s;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
