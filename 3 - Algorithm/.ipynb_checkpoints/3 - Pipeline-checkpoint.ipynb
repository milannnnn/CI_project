{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Data Importing and Helper Function Definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "DATA_folder  = '../../Data/'\n",
    "data = np.load(DATA_folder+'train_imgs.npy')\n",
    "lbls = np.load(DATA_folder+'train_lbls.npy')\n",
    "test_data = np.load(DATA_folder+'test_imgs.npy')\n",
    "test_lbls = np.load(DATA_folder+'test_lbls.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5923, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[lbls==0,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Definition of RBF Transformer Object:\n",
    "\n",
    "RBF Transformer is a scikit-learn compatible transformer object that implements:\n",
    "\n",
    "    - fit method       - clusters the digit-separated data, and computes cluster centers and inv. sq. deviations\n",
    "    - transform method - based on obtained centers and deviations it computes the fi values (RBF layer outputs) as \n",
    "                         simple Gaussian functions -> Fi_k(x) = exp{ -sqrt( sum[ (x_i-c_k_i)/(dev_i^2) ] ) } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of Clustering Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Clustering:\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Function for data clustering, and computation of cluster center vectors and inv. sq. deviation vectors\n",
    "def form_clusters(data, n_kmeans):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_kmeans, random_state=0, init='k-means++', algorithm='elkan')\n",
    "    lbls_kmeans = kmeans.fit_predict(data)\n",
    "    \n",
    "    lbls_set = [lbls_kmeans] # just as an option to include more clustering methods\n",
    "    \n",
    "    centers   = []\n",
    "    inv_sq_devs  = []\n",
    "    \n",
    "    # Find cluster centers and covar matrix:\n",
    "    for lbls in lbls_set:\n",
    "        for k in range(max(lbls)+1):\n",
    "#             # Ignore single element clusters (we cannot determine the spread)\n",
    "#             if(sum(lbls==k)>=2):\n",
    "#                 # print(k, sum(lbls==k),'elems')\n",
    "#                 cluster = data[lbls==k,:]\n",
    "#                 centers.append(cluster.mean(axis=0))\n",
    "#                 dev = np.std(data,axis=0)\n",
    "#                 dev[dev==0]+=1e-6 # to avoid Infs and NaNs\n",
    "#                 inv_sq_devs.append(np.reciprocal(np.square(dev)))\n",
    "#             else:\n",
    "#                 print('ignored')\n",
    "            \n",
    "            cluster = data[lbls==k,:]\n",
    "            centers.append(cluster.mean(axis=0))\n",
    "            dev = np.std(cluster,axis=0)\n",
    "            dev[dev==0]+=1e-3 # to avoid Infs and NaNs\n",
    "            inv_sq_devs.append(np.reciprocal(np.square(dev)))\n",
    "            \n",
    "        del cluster, dev\n",
    "    return centers, inv_sq_devs;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of RBF (Fi) Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate one Fi column for given dataset (for one RB center)\n",
    "def calc_fi_column(data, center, inv_sq_devs):\n",
    "    # data        - given dataset matrix for which to compute fi values\n",
    "    # center      - given center vector on which to compute fi vals\n",
    "    # inv_sq_devs - given reciprocal sq. deviation vector on which to compute fi vals \n",
    "    \n",
    "    fi_col = np.empty((data.shape[0],1))\n",
    "    # tmp  = data - np.dot(np.ones((data.shape[0],1)),center.reshape((1,center.shape[0])))\n",
    "    # tmp2 = np.square(tmp)\n",
    "    # tmp3 = np.dot(tmp2,inv_sq_devs)\n",
    "    # fi_col = np.exp(-np.sqrt(tmp3))\n",
    "    fi_col = np.exp(-np.sqrt(np.dot(np.square(data - np.dot(np.ones((data.shape[0],1)),center.reshape((1,center.shape[0])))),inv_sq_devs)))\n",
    "\n",
    "    return fi_col;\n",
    "\n",
    "# Function to compute whole Fi output for given dataset (for all RB centers)\n",
    "def fi_transform(data, all_centers, all_inv_sq_devs):\n",
    "    # data        - given dataset matrix for which to compute fi values\n",
    "    # center      - list of all center vectors on which to compute fi vals\n",
    "    # inv_sq_devs - list of all reciprocal sq. deviation vectors on which to compute fi vals     \n",
    "    new_data = np.empty((data.shape[0],len(all_centers)))\n",
    "    for k in range(len(all_centers)):\n",
    "        new_data[:,k] = calc_fi_column(data, all_centers[k], all_inv_sq_devs[k])\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of RBF Transformer (sklearn compatible object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/classes.html#module-sklearn.base\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "# SKLEARN Compatible Transformer - supports fit method (custering data) and transform method (calculating fi values)\n",
    "class myRBFtransformer(TransformerMixin):\n",
    "    \n",
    "    # Transformer initialization (default to 50 kMeans clusters)\n",
    "    def __init__(self, n_kmeans=50):\n",
    "        self.centers     = []\n",
    "        self.inv_sq_devs = []\n",
    "        self.n_kmeans    = n_kmeans\n",
    "        print(self.n_kmeans)\n",
    "    \n",
    "    # Clusters each digit and finds cluster centers and deviations:\n",
    "    def fit(self, X, y):\n",
    "        self.centers  = []\n",
    "        self.inv_sq_devs = []\n",
    "        for dig in range(10):\n",
    "            print('Current dig: ',dig)\n",
    "            data = X[y==dig,:]\n",
    "            centers, inv_sq_devs = form_clusters(data, self.n_kmeans)\n",
    "            self.centers.extend(centers)\n",
    "            self.inv_sq_devs.extend(inv_sq_devs)\n",
    "        return self\n",
    "    \n",
    "    # Computes fi values (with Gaussian function) based on obtained cluster centers and deviations:\n",
    "    def transform(self, X, y=None):\n",
    "        result = fi_transform(X, self.centers, self.inv_sq_devs)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Test:\n",
    "# rbf = myRBFtransformer(n_kmeans = 10)\n",
    "# a   = rbf.fit_transform(X=data[:500,:],y=lbls[:500])\n",
    "# a.max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Pipelining the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "\n",
    "n_pca    = 545 # First dimension to retain 99 % variance (stanford edu recomendation for images)!!!\n",
    "n_kmeans = 500\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "pca     = PCA(n_components=n_pca, whiten=True)\n",
    "rbf     = myRBFtransformer(n_kmeans=n_kmeans)\n",
    "scaler2 = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# my_pipe = Pipeline(steps=[('scal1', scaler1), ('pca', pca), ('rbf',rbf)])\n",
    "my_pipe = Pipeline(steps=[('scal1', scaler1), ('pca', pca), ('rbf',rbf), ('scal2',scaler2)])\n",
    "# my_pipe = Pipeline(steps=[('scal1', scaler1), ('pca', pca), ('rbf',rbf), ('scal2',scaler2), ('',)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dig:  0\n",
      "Current dig:  1\n",
      "Current dig:  2\n",
      "Current dig:  3\n",
      "Current dig:  4\n",
      "Current dig:  5\n",
      "Current dig:  6\n",
      "Current dig:  7\n",
      "Current dig:  8\n",
      "Current dig:  9\n"
     ]
    }
   ],
   "source": [
    "output = my_pipe.fit_transform(X=test_data,y=test_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=12, solver='newton-cg', tol=1e-08, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logreg = LogisticRegression(tol=1e-32,C=1e32,random_state=12,solver='newton-cg',multi_class ='multinomial')\n",
    "# 81.6%\n",
    "\n",
    "# logreg = LogisticRegression(tol=1e-32,C=1e32,random_state=12,solver='newton-cg',multi_class ='multinomial')\n",
    "# 97.25% with kmeans = 500\n",
    "# logreg = LogisticRegression(tol=1e-8,C=1e8,random_state=12,solver='newton-cg',multi_class ='multinomial')\n",
    "# 97.53% with kmeans = 500\n",
    "\n",
    "\n",
    "# logreg = LogisticRegression(tol=1e-32,C=1e32,random_state=12,solver='liblinear',penalty ='l2')\n",
    "logreg = LogisticRegression(tol=1e-8,C=1e8,random_state=12,solver='newton-cg',multi_class ='multinomial')\n",
    "logreg.fit(output, test_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.53\n"
     ]
    }
   ],
   "source": [
    "print(logreg.score(output, test_lbls)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rbf.inv_sq_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2419.77261729 37.3678331685\n",
      "14875134.7086 11550921.0157\n",
      "545000000.0 1000000.0\n",
      "2735.99161462 43.5901557541\n",
      "545000000.0 1000000.0\n",
      "25825599.7362 24882701.3224\n",
      "6618.407122 414.530832976\n",
      "6426.46170319 863.872686617\n",
      "1935.88580736 14.1264500513\n",
      "545000000.0 1000000.0\n",
      "5571233.06201 3676471.16608\n",
      "2872.27812089 30.9720514845\n",
      "545000000.0 1000000.0\n",
      "3668.63504196 220.608893547\n",
      "2769.41449403 47.0061073948\n",
      "545000000.0 1000000.0\n",
      "39718.1761875 14578.63452\n",
      "2877.27653898 59.6199323023\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "5766.66589241 570.600887492\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "4657.97854652 146.115343634\n",
      "3673.01439666 52.1818080363\n",
      "2576945777.12 2574180424.7\n",
      "2913277.13086 1267544.07536\n",
      "2695037.57043 1104292.66238\n",
      "545000000.0 1000000.0\n",
      "4017.6193854 266.99069881\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "2067.83048787 39.513300241\n",
      "545000000.0 1000000.0\n",
      "3391.30250061 198.229867493\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "36164695.6554 30898829.0937\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "545000000.0 1000000.0\n",
      "6262.72911986 678.797479908\n",
      "541855.654139 220730.791417\n",
      "3521398503.79 3302603451.3\n"
     ]
    }
   ],
   "source": [
    "for k in range(50):\n",
    "    print(sum(a[k]),a[k].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=np.arange(5)\n",
    "np.std(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
