{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Data Importing and Helper Function Definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "DATA_folder  = '../../Data/'\n",
    "data = np.load(DATA_folder+'train_imgs.npy')/1.0\n",
    "lbls = np.load(DATA_folder+'train_lbls.npy')\n",
    "test_data = np.load(DATA_folder+'test_imgs.npy')/1.0\n",
    "test_lbls = np.load(DATA_folder+'test_lbls.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[lbls==0,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Definition of RBF Transformer Object:\n",
    "\n",
    "RBF Transformer is a scikit-learn compatible transformer object that implements:\n",
    "\n",
    "    - fit method       - clusters the digit-separated data, and computes cluster centers and inv. sq. deviations\n",
    "    - transform method - based on obtained centers and deviations it computes the fi values (RBF layer outputs) as \n",
    "                         simple Gaussian functions -> Fi_k(x) = exp{ -sqrt( sum[ (x_i-c_k_i)/(dev_i^2) ] ) } \n",
    "                         \n",
    "## Normalizing each Fi row with row sum -> STABILIZED the Regression a lot!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of Clustering Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Clustering:\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Function for data clustering, and computation of cluster center vectors and inv. sq. deviation vectors\n",
    "def form_clusters(data, n_kmeans):\n",
    "    \n",
    "    n_clst = min(n_kmeans,data.shape[0])\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clst, random_state=0, init='k-means++', algorithm='elkan')\n",
    "    lbls_kmeans = kmeans.fit_predict(data)\n",
    "    \n",
    "    lbls_set = [lbls_kmeans] # just as an option to include more clustering methods\n",
    "    \n",
    "    centers   = []\n",
    "    inv_sq_devs  = []\n",
    "    \n",
    "    # Find cluster centers and covar matrix:\n",
    "    for lbls in lbls_set:\n",
    "        for k in range(max(lbls)+1):\n",
    "            \n",
    "            cluster = data[lbls==k,:]\n",
    "            centers.append(cluster.mean(axis=0))\n",
    "            dev = np.std(cluster,axis=0)\n",
    "            dev[dev==0]+=1e-3 # to avoid Infs and NaNs\n",
    "            inv_sq_devs.append(np.reciprocal(np.square(dev)))\n",
    "            \n",
    "        del cluster, dev\n",
    "    return centers, inv_sq_devs;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of RBF (Fi) Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to compute whole Fi output for given dataset (for all RB centers)\n",
    "def fi_transform(data, all_centers, all_inv_sq_devs):\n",
    "    # data        - given dataset matrix for which to compute fi values\n",
    "    # center      - list of all center vectors on which to compute fi vals\n",
    "    # inv_sq_devs - list of all reciprocal sq. deviation vectors on which to compute fi vals     \n",
    "\n",
    "    new_data = np.empty((data.shape[0],len(all_centers)))\n",
    "    st = 0\n",
    "    ch = 200\n",
    "    ns = data.shape[0]\n",
    "    # Process data in chunks of 200 smpls (optimal speed)\n",
    "    while st<ns:\n",
    "        en = min(st+ch,ns)\n",
    "        for k in range(len(all_centers)):\n",
    "            # new_data[st:en,k] = calc_fi_column(data[st:en], all_centers[k], all_inv_sq_devs[k])\n",
    "            new_data[st:en,k] = np.dot(np.square(data[st:en] - np.repeat(all_centers[k][np.newaxis,:],data[st:en].shape[0],axis=0)),all_inv_sq_devs[k])\n",
    "        st = en\n",
    "    new_data = np.exp(-np.sqrt(new_data))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of RBF Transformer (sklearn compatible object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/classes.html#module-sklearn.base\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# SKLEARN Compatible Transformer - supports fit method (custering data) and transform method (calculating fi values)\n",
    "class myRBFtransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # Transformer initialization (default to 50 kMeans clusters)\n",
    "    def __init__(self, kmeans_ratio=0.5, n_fi_max=10):\n",
    "        self.kmeans_ratio = kmeans_ratio # ratio used to calc the number of clusters (n=r*smpls/10)\n",
    "        self.n_fi_max     = n_fi_max     # num of max fi vals to return per digit\n",
    "        self.centers      = []           # list of cluster center vectors\n",
    "        self.inv_sq_devs  = []           # list of cluster inv. sq. dev. vectors\n",
    "        self.num_centers  = []           # list of number of centers per digit\n",
    "        # print(self.kmeans_ratio,self.n_fi_max)\n",
    "    \n",
    "    # Clusters each digit and finds cluster centers and deviations:\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.centers     = []\n",
    "        self.inv_sq_devs = []\n",
    "        self.num_centers = []\n",
    "        \n",
    "        # Calc. num. of clusters per digit based on assigned ratio (ratio*(num of smpls / 10))\n",
    "        n_kmeans = max(round(self.kmeans_ratio*X.shape[0]/10), 1)\n",
    "        # print(n_kmeans)\n",
    "        \n",
    "        # Cluster the data over each digit\n",
    "        for dig in range(10):\n",
    "            # print('Clustering digit: ',dig)\n",
    "            data = X[y==dig,:]\n",
    "            centers, inv_sq_devs = form_clusters(data, n_kmeans)\n",
    "            self.centers.extend(centers)\n",
    "            self.inv_sq_devs.extend(inv_sq_devs)\n",
    "            self.num_centers.append(len(centers))\n",
    "        \n",
    "        # Limit the n_fi_max to the min. number of centers per digit \n",
    "        self.n_fi_max = min(self.n_fi_max,min(self.num_centers))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # Computes fi values (with Gaussian function) based on obtained cluster centers and deviations\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Compute all Fi values:\n",
    "        # print('- Calculating all fi outputs !!!')\n",
    "        all_fis = fi_transform(X, self.centers, self.inv_sq_devs)\n",
    "        \n",
    "        # Find n max fi vals over each digit:\n",
    "        # print('- Selecting n max fi outputs !!!')\n",
    "        n_max  = self.n_fi_max\n",
    "        result = np.empty((X.shape[0],n_max*10))\n",
    "        start  = 0\n",
    "        for k in range(10):\n",
    "            end = start + self.num_centers[k]\n",
    "            result[:,(k*n_max):((k+1)*n_max)] = np.sort(all_fis[:,start:end],axis=1)[:,-n_max:]\n",
    "            start = end\n",
    "        del all_fis\n",
    "        \n",
    "        # Normalize each row with the sum of that row's elements:\n",
    "        # result = np.divide(result,np.sum(result,axis=1).reshape((result.shape[0],1)))\n",
    "        row_sum = np.sum(result,axis=1).reshape((result.shape[0],1))\n",
    "        row_sum[row_sum==0]=1e-12\n",
    "        result = np.divide(result,row_sum)\n",
    "        # print('Transform finished !!!')\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Test:\n",
    "# rbf = myRBFtransformer(n_kmeans = 10)\n",
    "# a   = rbf.fit_transform(X=data[:500,:],y=lbls[:500])\n",
    "# a.max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Pipelining the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "\n",
    "n_pca        = 545 # First dimension to retain 99 % variance (stanford edu recomendation for images)!!!\n",
    "kmeans_ratio = 1\n",
    "n_fi_max     = 10\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca    = PCA(n_components=n_pca, whiten=True)\n",
    "rbf    = myRBFtransformer(kmeans_ratio=kmeans_ratio,n_fi_max=n_fi_max)\n",
    "logreg = LogisticRegression(tol=1e-12,C=1e+12,random_state=12,solver='liblinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "my_pipe = Pipeline(steps=[('scal1', scaler), ('pca', pca), ('rbf',rbf), ('logreg',logreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lbls = my_pipe.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(pred_lbls==test_lbls)/len(test_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "from dask_searchcv import GridSearchCV\n",
    "\n",
    "Ks = [0.1, 0.3, 0.5, 0.8]\n",
    "Ns = [3, 7, 10, 15]\n",
    "Cs = [1e3, 1e6, 1e9, 1e12]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'rbf__kmeans_ratio': Ks,\n",
    "        'rbf__n_fi_max':     Ns,\n",
    "        'logreg__C':         Cs\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(my_pipe, cv=3, n_jobs=-1, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(test_data[:], test_lbls[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### For this grid\n",
    "# Ks = [0.1, 0.3, 0.5, 0.8]\n",
    "# Ns = [3, 7, 10, 15]\n",
    "# Cs = [1e3, 1e6, 1e9, 1e12]\n",
    "# # Best set was\n",
    "# K = 0.1\n",
    "# N = 15\n",
    "# C = 1e9\n",
    "# # at 71.79%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(grid.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
